{
  "permissions": {
    "allow": [
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\":*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main maintenance list test-projects/spring-petclinic-microservices)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main:*)",
      "Bash(dir /s /b test-projectsspring-petclinic-microservices*.java)",
      "Bash(dir:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main tests analyze test-projects/spring-petclinic-microservices --verbose)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main deploy:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main tests generate test-projects/spring-petclinic-microservices --verbose)",
      "Bash(del:*)",
      "Bash(git add:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nfeat: Add LLM-powered test generation with template fallback\n\nMajor changes:\n- Add LLM mode for intelligent test generation (production)\n- Add template mode for CI without LLM access (use_llm=False)\n- Delete deprecated workflows: docker_deployment.py, maven_maintenance.py, test_generation.py\n- Add CONTEXT.md for project documentation\n\nTest generation now uses LLM by default:\n- generate_adaptive_tests(use_llm=True) - LLM-powered tests\n- generate_adaptive_tests(use_llm=False) - Template-based tests\n\nFallback: If LLM fails, automatically uses template generation.\n\nü§ñ Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(git commit -m \"$(cat <<''EOF''\ndocs: Update CONTEXT.md with complete project reference\n\n- Add LLM configuration section with YAML example\n- Add provider options (google-genai, anthropic, openai)\n- Add Key Functions table for test generation\n- Add Quick Reference with code examples\n- Improve structure with tables for better readability\n\nü§ñ Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(powershell -ExecutionPolicy Bypass -File:*)",
      "Bash(cat:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/ -v --tb=short)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/db/test_crud.py tests/unit/test_session_purge.py -v --tb=short)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/ -v --no-cov)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" --version)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main --version)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main tests analyze test-projects/java-maven-junit-helloworld)",
      "Bash(curl:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main serve --port 8000)",
      "Bash(timeout /t 5 /nobreak)",
      "Bash(powershell -Command \"Start-Sleep -Seconds 5; curl -s http://localhost:8000/health\")",
      "Bash(powershell -Command \"Start-Sleep -Seconds 5; Invoke-WebRequest -Uri ''http://localhost:8000/health'' -UseBasicParsing | Select-Object -ExpandProperty Content\")",
      "Bash(powershell -Command:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\n\nBASE = ''http://localhost:8000''\n\n# API-S01: Create session\nprint\\(''=== API-S01: Create Session ===''\\)\nr = requests.post\\(f''{BASE}/api/v2/sessions'', json={\n    ''project_path'': ''test-projects/spring-petclinic-microservices'',\n    ''session_type'': ''test_generation'',\n    ''mode'': ''interactive''\n}, headers={''X-API-Key'': ''test-key''}\\)\nprint\\(f''Status: {r.status_code}''\\)\nprint\\(f''Response: {json.dumps\\(r.json\\(\\), indent=2\\)[:500]}''\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\n\nBASE = ''http://localhost:8000''\nAPI_KEY = ''your-api-key-here''\n\n# API-M01: Metrics endpoint \\(correct path\\)\nprint\\(''=== API-M01: Metrics Endpoint ===''\\)\nr = requests.get\\(f''{BASE}/metrics/json'', headers={''X-API-Key'': API_KEY}\\)\nprint\\(f''Status: {r.status_code}''\\)\nif r.status_code == 200:\n    print\\(f''Response: {json.dumps\\(r.json\\(\\), indent=2\\)[:800]}''\\)\nelse:\n    print\\(f''Response: {r.text}''\\)\n\n# Test steps endpoints\nprint\\(\\)\nprint\\(''=== API-S05: Session Steps ===''\\)\n# Create a session first\nr1 = requests.post\\(f''{BASE}/api/v2/sessions'', json={\n    ''project_path'': ''test-projects/spring-petclinic-microservices'',\n    ''session_type'': ''maven_maintenance'',\n    ''mode'': ''interactive''\n}, headers={''X-API-Key'': API_KEY}\\)\n\nif r1.status_code == 201:\n    session_id = r1.json\\(\\).get\\(''id''\\)\n    \n    # Get steps\n    r2 = requests.get\\(f''{BASE}/api/v2/sessions/{session_id}/steps'', headers={''X-API-Key'': API_KEY}\\)\n    print\\(f''Get Steps Status: {r2.status_code}''\\)\n    print\\(f''Steps: {json.dumps\\(r2.json\\(\\), indent=2\\)[:400]}''\\)\n\")",
      "Bash(rm:*)",
      "Bash(git push:*)",
      "Bash(ruff check:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check tests/ --output-format=concise)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check tests/ --fix --unsafe-fixes)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff format:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pip install pytest-rerunfailures)",
      "Bash(git commit:*)",
      "Bash(claude:*)",
      "Bash(npm view:*)",
      "Bash(git fetch:*)",
      "Bash(findstr:*)",
      "Bash(powershell -ExecutionPolicy Bypass -Command \"& ''.\\\\.specify\\\\scripts\\\\powershell\\\\create-new-feature.ps1'' -Number 6 -ShortName ''file-modifications-api'' -Json ''API Endpoints for File Modifications Tracking - Add artifact content download endpoint and file_modification artifact type''\")",
      "Bash(powershell -ExecutionPolicy Bypass -Command \"& ''.\\\\.specify\\\\scripts\\\\powershell\\\\check-prerequisites.ps1'' -Json -PathsOnly\")",
      "Bash(powershell -ExecutionPolicy Bypass -Command \"& ''.\\\\.specify\\\\scripts\\\\powershell\\\\setup-plan.ps1'' -Json\")",
      "Bash(powershell -ExecutionPolicy Bypass -Command:*)",
      "Bash(docker compose:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m alembic upgrade head)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/lib/diff.py src/api/routers/sessions.py src/core/session.py src/db/models/artifact.py --output-format=concise)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/lib/diff.py src/api/routers/sessions.py src/core/session.py src/db/models/artifact.py --fix)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m mypy src/lib/diff.py src/api/routers/sessions.py --ignore-missing-imports)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m mypy src/lib/diff.py src/api/routers/sessions.py src/db/models/artifact.py --ignore-missing-imports)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/test_session_service.py -v --tb=short)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/test_workflow_steps.py -v --tb=short --no-cov)",
      "Bash(taskkill:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/api/routers/sessions.py --output-format=concise)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/api/routers/sessions.py src/core/step_executor.py --output-format=concise)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/api/routers/sessions.py src/core/step_executor.py --fix)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/ -v --tb=short --no-cov -x)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/workflows/ -v --tb=short --no-cov)",
      "Bash(\"c:/Users/jfran/axtion\\\\TestBoost/.venv/Scripts/python.exe\" -m pytest:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" scripts/detect_unlogged_exceptions.py)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/test_workflow_documentation.py tests/unit/test_session_service.py -v --tb=short --no-cov)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" scripts/detect_unlogged_exceptions.py --check-only)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check scripts/detect_unlogged_exceptions.py --fix)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/api/middleware/logging.py --output-format=concise)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/unit/api/ -v --tb=short --no-cov -x -q)",
      "Bash(python -m json.tool:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy import text\n\nasync def check_session\\(\\):\n    engine = create_async_engine\\(''postgresql+asyncpg://testboost:testboost@localhost:5433/testboost''\\)\n    async with engine.begin\\(\\) as conn:\n        result = await conn.execute\\(\n            text\\(''''''\n                SELECT id, status\n                FROM sessions\n                WHERE id = ''08523ac9-70ee-4d37-8d48-becb657b0c69''\n            ''''''\\)\n        \\)\n        for row in result:\n            print\\(f''Session: {row[0]}, Status: {row[1]}''\\)\n\nasyncio.run\\(check_session\\(\\)\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy import text\n\nasync def analyze_workflow\\(\\):\n    engine = create_async_engine\\(''postgresql+asyncpg://testboost:testboost@localhost:5433/testboost''\\)\n    async with engine.begin\\(\\) as conn:\n        # V√©rifier les steps de la session\n        result = await conn.execute\\(\n            text\\(''''''\n                SELECT code, name, status, outputs\n                FROM steps\n                WHERE session_id = ''08523ac9-70ee-4d37-8d48-becb657b0c69''\n                ORDER BY sequence\n            ''''''\\)\n        \\)\n        print\\(''\\\\nSteps de la session:''\\)\n        for row in result:\n            print\\(f''  {row[0]}: {row[1]} [{row[2]}]''\\)\n            if row[3]:\n                print\\(f''    Outputs keys: {list\\(row[3].keys\\(\\)\\)}''\\)\n\nasyncio.run\\(analyze_workflow\\(\\)\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/workflows/test_generation_agent.py --select F,E)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" test_artifact_fix.py)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/workflows/test_generation_agent.py --output-format=concise)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\n\nBASE = ''http://localhost:8000''\nAPI_KEY = ''your-api-key-here''\n\n# Get session details\nprint\\(''=== Session Details ===''\\)\nr = requests.get\\(\n    f''{BASE}/api/v2/sessions/8735fd97-77eb-419f-8891-c413da709c7b'',\n    headers={''X-API-Key'': API_KEY}\n\\)\nprint\\(f''Status: {r.status_code}''\\)\nif r.status_code == 200:\n    data = r.json\\(\\)\n    print\\(f''Session Status: {data.get\\(\"\"status\"\"\\)}''\\)\n    print\\(f''Project Path: {data.get\\(\"\"project_path\"\"\\)}''\\)\n    print\\(f''Session Type: {data.get\\(\"\"session_type\"\"\\)}''\\)\n    print\\(json.dumps\\(data, indent=2\\)[:800]\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy import text\n\nasync def check_step\\(\\):\n    engine = create_async_engine\\(''postgresql+asyncpg://testboost:testboost@localhost:5433/testboost''\\)\n    async with engine.begin\\(\\) as conn:\n        result = await conn.execute\\(\n            text\\(''''''\n                SELECT code, status, outputs, error_message, updated_at\n                FROM steps\n                WHERE session_id = ''8735fd97-77eb-419f-8891-c413da709c7b''\n                AND code = ''analyze_project''\n            ''''''\\)\n        \\)\n        step = result.fetchone\\(\\)\n        if step:\n            print\\(f''Step: {step[0]}''\\)\n            print\\(f''Status: {step[1]}''\\)\n            print\\(f''Error: {step[3]}''\\)\n            print\\(f''Updated: {step[4]}''\\)\n            if step[2]:\n                import json\n                print\\(f''Outputs: {json.dumps\\(step[2], indent=2\\)[:500]}''\\)\n\nasyncio.run\\(check_step\\(\\)\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy import text\nimport json\n\nasync def check\\(\\):\n    engine = create_async_engine\\(''postgresql+asyncpg://testboost:testboost@localhost:5433/testboost''\\)\n    async with engine.begin\\(\\) as conn:\n        result = await conn.execute\\(\n            text\\(''''''\n                SELECT outputs\n                FROM steps\n                WHERE session_id = ''b2752ab9-ce42-4401-8fc4-4eb85e9d5f26''\n                AND code = ''analyze_project''\n            ''''''\\)\n        \\)\n        step = result.fetchone\\(\\)\n        if step and step[0]:\n            print\\(''analyze_project outputs:''\\)\n            print\\(json.dumps\\(step[0], indent=2\\)[:1500]\\)\n\nasyncio.run\\(check\\(\\)\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/core/step_executor.py src/lib/llm.py src/lib/llm_callbacks.py --output-format=concise)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/core/step_executor.py src/lib/llm.py src/lib/llm_callbacks.py --fix)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\nimport time\n\nBASE = ''http://localhost:8000''\nAPI_KEY = ''your-api-key-here''\n\n# Create new session\nprint\\(''=== Creating Test Session ===''\\)\nr = requests.post\\(\n    f''{BASE}/api/v2/sessions'',\n    headers={''X-API-Key'': API_KEY},\n    json={\n        ''project_path'': ''test-projects/java-maven-junit-helloworld'',\n        ''session_type'': ''test_generation'',\n        ''mode'': ''interactive''\n    }\n\\)\n\nif r.status_code != 201:\n    print\\(f''Failed: {r.text}''\\)\n    exit\\(1\\)\n\nsession_id = r.json\\(\\)[''id'']\nprint\\(f''Session: {session_id}''\\)\n\n# Execute analyze_project step\nprint\\(''\\\\n=== Executing analyze_project ===''\\)\nr = requests.post\\(\n    f''{BASE}/api/v2/sessions/{session_id}/steps/analyze_project/execute'',\n    headers={''X-API-Key'': API_KEY},\n    json={''run_workflow'': True, ''run_in_background'': False}\n\\)\n\nif r.status_code == 200:\n    print\\(f''Status: {r.json\\(\\)[\"\"status\"\"]}''\\)\n    \n    # Wait a bit and check Prometheus\n    time.sleep\\(2\\)\n    \n    print\\(''\\\\n=== Checking Prometheus Metrics ===''\\)\n    \n    # Check workflow metrics\n    r = requests.get\\(''http://localhost:9090/api/v1/query'', params={\n        ''query'': ''testboost_workflow_total''\n    }\\)\n    if r.status_code == 200:\n        result = r.json\\(\\).get\\(''data'', {}\\).get\\(''result'', []\\)\n        if result:\n            print\\(f''\\\\nWorkflow metrics found: {len\\(result\\)} series''\\)\n            for m in result[:3]:\n                print\\(f''  {m[\"\"metric\"\"].get\\(\"\"workflow_type\"\"\\)} [{m[\"\"metric\"\"].get\\(\"\"status\"\"\\)}] = {m[\"\"value\"\"][1]}''\\)\n        else:\n            print\\(''\\\\nNo workflow metrics yet''\\)\n    \n    # Check LLM metrics  \n    r = requests.get\\(''http://localhost:9090/api/v1/query'', params={\n        ''query'': ''testboost_llm_calls_total''\n    }\\)\n    if r.status_code == 200:\n        result = r.json\\(\\).get\\(''data'', {}\\).get\\(''result'', []\\)\n        if result:\n            print\\(f''\\\\nLLM metrics found: {len\\(result\\)} series''\\)\n            for m in result[:3]:\n                print\\(f''  {m[\"\"metric\"\"].get\\(\"\"provider\"\"\\)} / {m[\"\"metric\"\"].get\\(\"\"model\"\"\\)} [{m[\"\"metric\"\"].get\\(\"\"status\"\"\\)}] = {m[\"\"value\"\"][1]}''\\)\n        else:\n            print\\(''\\\\nNo LLM metrics yet''\\)\nelse:\n    print\\(f''Failed: {r.text}''\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\n\nprint\\(''=== Checking /metrics Endpoint ===''\\)\nr = requests.get\\(''http://localhost:8000/metrics''\\)\nif r.status_code == 200:\n    lines = r.text.split\\(''\\\\n''\\)\n    \n    # Find workflow metrics\n    workflow_lines = [l for l in lines if ''testboost_workflow'' in l and not l.startswith\\(''#''\\)]\n    if workflow_lines:\n        print\\(''\\\\nWorkflow Metrics:''\\)\n        for line in workflow_lines[:10]:\n            print\\(f''  {line}''\\)\n    else:\n        print\\(''\\\\nNo workflow metrics in /metrics''\\)\n    \n    # Find LLM metrics\n    llm_lines = [l for l in lines if ''testboost_llm'' in l and not l.startswith\\(''#''\\)]\n    if llm_lines:\n        print\\(''\\\\nLLM Metrics:''\\)\n        for line in llm_lines[:10]:\n            print\\(f''  {line}''\\)\n    else:\n        print\\(''\\\\nNo LLM metrics in /metrics''\\)\nelse:\n    print\\(f''Failed to get metrics: {r.status_code}''\\)\n\")",
      "Bash(timeout /t 2 /nobreak)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m src.cli.main serve:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\n\nprint\\(''=== VERIFICATION PROMETHEUS ===\\\\n''\\)\n\n# Check workflow metrics in Prometheus\nqueries = [\n    \\(''testboost_workflow_total'', ''Workflow Total''\\),\n    \\(''testboost_workflow_duration_seconds_count'', ''Workflow Duration Count''\\),\n    \\(''testboost_llm_calls_total'', ''LLM Calls''\\),\n    \\(''testboost_llm_request_duration_seconds_sum'', ''LLM Duration''\\),\n]\n\nfor query, name in queries:\n    r = requests.get\\(''http://localhost:9090/api/v1/query'', params={''query'': query}\\)\n    if r.status_code == 200:\n        result = r.json\\(\\).get\\(''data'', {}\\).get\\(''result'', []\\)\n        if result:\n            print\\(f''{name}: {len\\(result\\)} series''\\)\n            for metric in result[:2]:\n                labels = metric.get\\(''metric'', {}\\)\n                value = metric.get\\(''value'', [None, None]\\)[1]\n                key_labels = {k: v for k, v in labels.items\\(\\) if k not in [''__name__'', ''instance'', ''job'']}\n                print\\(f''  {key_labels} = {value}''\\)\n        else:\n            print\\(f''{name}: Pas encore dans Prometheus \\(attente du scrape\\)''\\)\n    print\\(\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\nimport time\n\nBASE = ''http://localhost:8000''\nAPI_KEY = ''your-api-key-here''\n\n# Create session\nprint\\(''=== Creating Test Session ===''\\)\nr = requests.post\\(\n    f''{BASE}/api/v2/sessions'',\n    headers={''X-API-Key'': API_KEY},\n    json={\n        ''project_path'': ''test-projects/java-maven-junit-helloworld'',\n        ''session_type'': ''test_generation'',\n        ''mode'': ''interactive''\n    }\n\\)\n\nif r.status_code != 201:\n    print\\(f''Failed: {r.status_code} - {r.text}''\\)\n    exit\\(1\\)\n\nsession_id = r.json\\(\\)[''id'']\nprint\\(f''Session: {session_id}''\\)\n\n# Execute analyze_project\nprint\\(''\\\\n=== Executing analyze_project ===''\\)\nr = requests.post\\(\n    f''{BASE}/api/v2/sessions/{session_id}/steps/analyze_project/execute'',\n    headers={''X-API-Key'': API_KEY},\n    json={''run_workflow'': True, ''run_in_background'': False}\n\\)\n\nif r.status_code == 200:\n    print\\(f''Started''\\)\n    \n    # Wait for completion\n    for i in range\\(120\\):\n        time.sleep\\(3\\)\n        r = requests.get\\(\n            f''{BASE}/api/v2/sessions/{session_id}/steps'',\n            headers={''X-API-Key'': API_KEY}\n        \\)\n        if r.status_code == 200:\n            steps = r.json\\(\\)[''items'']\n            \n            # Find generate_tests step\n            gen_step = next\\(\\(s for s in steps if s[''code''] == ''generate_tests''\\), None\\)\n            if gen_step:\n                status = gen_step.get\\(''status''\\)\n                print\\(f''  [{i*3}s] generate_tests: {status}''\\)\n                \n                if status == ''completed'':\n                    outputs = gen_step.get\\(''outputs'', {}\\).get\\(''result'', {}\\)\n                    tests_gen = outputs.get\\(''tests_generated'', 0\\)\n                    print\\(f''\\\\n‚úÖ Tests generated: {tests_gen}''\\)\n                    break\n                elif status == ''failed'':\n                    print\\(f''\\\\n‚ùå Failed: {gen_step.get\\(\"\"error_message\"\"\\)}''\\)\n                    break\n        \n        if i >= 119:\n            print\\(''\\\\n‚è±Ô∏è Timeout''\\)\n            break\n    \n    # Check artifacts\n    print\\(''\\\\n=== Checking Artifacts ===''\\)\n    r = requests.get\\(\n        f''{BASE}/api/v2/sessions/{session_id}/artifacts'',\n        headers={''X-API-Key'': API_KEY}\n    \\)\n    if r.status_code == 200:\n        data = r.json\\(\\)\n        artifacts = data.get\\(''items'', []\\)\n        print\\(f''Total artifacts: {len\\(artifacts\\)}''\\)\n        \n        file_mods = [a for a in artifacts if a.get\\(''artifact_type''\\) == ''file_modification'']\n        print\\(f''file_modification artifacts: {len\\(file_mods\\)}''\\)\n        \n        if file_mods:\n            print\\(''\\\\nFirst 2 artifacts:''\\)\n            for art in file_mods[:2]:\n                meta = art.get\\(''metadata'', {}\\)\n                print\\(f''  - {art.get\\(\"\"name\"\"\\)}''\\)\n                print\\(f''    Path: {meta.get\\(\"\"file_path\"\"\\)}''\\)\n                print\\(f''    Operation: {meta.get\\(\"\"operation\"\"\\)}''\\)\n                print\\(f''    Diff: {len\\(meta.get\\(\"\"diff\"\", \"\"\"\"\\)\\)} chars''\\)\n                print\\(f''    Content: {len\\(meta.get\\(\"\"modified_content\"\", \"\"\"\"\\)\\)} chars''\\)\nelse:\n    print\\(f''Failed: {r.status_code} - {r.text}''\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\n\nBASE = ''http://localhost:8000''\nAPI_KEY = ''your-api-key-here''\n\n# Get the last session with artifacts\nr = requests.get\\(f''{BASE}/api/v2/sessions'', headers={''X-API-Key'': API_KEY}\\)\nif r.status_code == 200:\n    sessions = r.json\\(\\).get\\(''items'', []\\)\n    if sessions:\n        session = sessions[0]\n        session_id = session[''id'']\n        print\\(f''Testing with session: {session_id}''\\)\n        \n        # Get artifacts for this session\n        r = requests.get\\(\n            f''{BASE}/api/v2/sessions/{session_id}/artifacts'',\n            headers={''X-API-Key'': API_KEY}\n        \\)\n        \n        if r.status_code == 200:\n            artifacts = r.json\\(\\).get\\(''items'', []\\)\n            if artifacts:\n                artifact = artifacts[0]\n                artifact_id = artifact[''id'']\n                print\\(f''Testing with artifact: {artifact_id}''\\)\n                print\\(f''Artifact name: {artifact[\"\"name\"\"]}''\\)\n                print\\(f''Artifact type: {artifact[\"\"artifact_type\"\"]}''\\)\n                \n                # Test the correct URL\n                correct_url = f''{BASE}/api/v2/sessions/{session_id}/artifacts/{artifact_id}/content''\n                print\\(f''\\\\nTesting correct URL:''\\)\n                print\\(f''{correct_url}''\\)\n                \n                r = requests.get\\(correct_url, headers={''X-API-Key'': API_KEY}\\)\n                print\\(f''Status: {r.status_code}''\\)\n                \n                if r.status_code == 200:\n                    content_length = len\\(r.text\\)\n                    print\\(f''Content length: {content_length} chars''\\)\n                    print\\(f''Content-Type: {r.headers.get\\(\"\"content-type\"\"\\)}''\\)\n                    if content_length < 500:\n                        print\\(f''Content preview:\\\\n{r.text[:500]}''\\)\n                    else:\n                        print\\(f''Content preview \\(first 500 chars\\):\\\\n{r.text[:500]}...''\\)\n                else:\n                    print\\(f''Error: {r.text}''\\)\n            else:\n                print\\(''No artifacts found''\\)\n        else:\n            print\\(f''Failed to get artifacts: {r.status_code}''\\)\n    else:\n        print\\(''No sessions found''\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy import text\nimport json\n\nasync def check_artifact\\(\\):\n    engine = create_async_engine\\(''postgresql+asyncpg://testboost:testboost@localhost:5433/testboost''\\)\n    async with engine.begin\\(\\) as conn:\n        result = await conn.execute\\(\n            text\\(''''''\n                SELECT id, name, artifact_type, size_bytes,\n                       artifact_metadata IS NOT NULL as has_metadata,\n                       jsonb_typeof\\(artifact_metadata\\) as metadata_type,\n                       artifact_metadata\n                FROM artifacts\n                WHERE session_id = :session_id\n                AND artifact_type = :artifact_type\n                LIMIT 2\n            ''''''\\),\n            {''session_id'': ''0dccc5ce-dd0f-4b9f-ae53-1589f582ebdf'', ''artifact_type'': ''file_modification''}\n        \\)\n        \n        for row in result:\n            print\\(f''Artifact: {row[1]}''\\)\n            print\\(f''Type: {row[2]}''\\)\n            print\\(f''Size: {row[3]} bytes''\\)\n            print\\(f''Has metadata: {row[4]}''\\)\n            print\\(f''Metadata type: {row[5]}''\\)\n            \n            if row[6]:\n                metadata = row[6]\n                print\\(f''Metadata keys: {list\\(metadata.keys\\(\\)\\)}''\\)\n                \n                if ''modified_content'' in metadata:\n                    content = metadata[''modified_content'']\n                    if content:\n                        print\\(f''Modified content: {len\\(content\\)} chars''\\)\n                        print\\(f''Preview: {content[:100]}...''\\)\n                    else:\n                        print\\(''Modified content: EMPTY or NULL''\\)\n                else:\n                    print\\(''Modified content: NOT IN METADATA''\\)\n            else:\n                print\\(''Metadata: NULL''\\)\n            \n            print\\(\\)\n    \n    await engine.dispose\\(\\)\n\nasyncio.run\\(check_artifact\\(\\)\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport asyncio\nfrom sqlalchemy.ext.asyncio import create_async_engine\nfrom sqlalchemy import text\nimport json\n\nasync def check_artifact\\(\\):\n    engine = create_async_engine\\(''postgresql+asyncpg://testboost:testboost@localhost:5433/testboost''\\)\n    async with engine.begin\\(\\) as conn:\n        result = await conn.execute\\(\n            text\\(''''''\n                SELECT id, name, artifact_type, size_bytes,\n                       metadata IS NOT NULL as has_metadata,\n                       jsonb_typeof\\(metadata\\) as metadata_type,\n                       metadata\n                FROM artifacts\n                WHERE session_id = :session_id\n                AND artifact_type = :artifact_type\n                LIMIT 2\n            ''''''\\),\n            {''session_id'': ''0dccc5ce-dd0f-4b9f-ae53-1589f582ebdf'', ''artifact_type'': ''file_modification''}\n        \\)\n        \n        for row in result:\n            print\\(f''Artifact: {row[1]}''\\)\n            print\\(f''Type: {row[2]}''\\)\n            print\\(f''Size: {row[3]} bytes''\\)\n            print\\(f''Has metadata: {row[4]}''\\)\n            print\\(f''Metadata type: {row[5]}''\\)\n            \n            if row[6]:\n                metadata = row[6]\n                print\\(f''Metadata keys: {list\\(metadata.keys\\(\\)\\)}''\\)\n                \n                if ''modified_content'' in metadata:\n                    content = metadata[''modified_content'']\n                    if content:\n                        print\\(f''Modified content: {len\\(content\\)} chars''\\)\n                        print\\(f''Preview: {content[:100]}...''\\)\n                    else:\n                        print\\(''Modified content: EMPTY or NULL''\\)\n                else:\n                    print\\(''Modified content: NOT IN METADATA''\\)\n            else:\n                print\\(''Metadata: NULL''\\)\n            \n            print\\(\\)\n    \n    await engine.dispose\\(\\)\n\nasyncio.run\\(check_artifact\\(\\)\\)\n\")",
      "Skill(speckit.tasks)",
      "Skill(speckit.tasks:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m py_compile src/api/routers/sessions.py)",
      "Bash(\".venv\\\\Scripts\\\\python.exe\" -m pytest tests/unit/api/test_events_endpoint.py -v --no-cov)",
      "Bash(\".venv\\\\Scripts\\\\python.exe\" -m pytest tests/unit/ -v --tb=short --no-cov)",
      "Bash(\"C:\\\\Users\\\\jfran\\\\axtion\\\\TestBoost\\\\.venv\\\\Scripts\\\\python.exe\" -m py_compile src/api/routers/sessions.py)",
      "Bash(\".venv\\\\Scripts\\\\python.exe\" -m src.cli.main serve --port 8000)",
      "Bash(python -c:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m py_compile:*)",
      "Bash(netstat:*)",
      "Bash(cmd //c \"taskkill /PID 121056 /F & taskkill /PID 74504 /F\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"from src.api.routers import logs; print\\(''Import successful''\\); print\\(f''Router: {logs.router}''\\); print\\(f''Prefix: {logs.router.prefix}''\\)\")",
      "Bash(find:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -B -m src.cli.main serve --port 8000)",
      "Bash(cmd //c \"taskkill /F /PID 123968 & taskkill /F /PID 74504\")",
      "Bash(cmd //c \"taskkill /F /T /PID 74504\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -B -m src.cli.main serve --port 8001)",
      "Bash(cmd //c \"netstat -ano | findstr \"\":8001\"\" | findstr \"\"LISTENING\"\"\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\n\nBASE = ''http://localhost:8001''\nAPI_KEY = ''your-api-key-here''\n\nprint\\(''========================================''\\)\nprint\\(''  COMPREHENSIVE LOGS API TEST SUITE''\\)\nprint\\(''========================================''\\)\nprint\\(\\)\n\n# Test 1: Get all logs \\(default pagination\\)\nprint\\(''[1] GET /api/v2/logs \\(all logs, default pagination\\)''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}\\)\nassert r.status_code == 200, f''Expected 200, got {r.status_code}''\ndata = r.json\\(\\)\nprint\\(f''   Total logs: {data[\"\"total\"\"]}''\\)\nprint\\(f''   Returned: {len\\(data[\"\"logs\"\"]\\)} \\(page {data[\"\"page\"\"]}, {data[\"\"per_page\"\"]} per page\\)''\\)\nprint\\(f''   PASS''\\)\nprint\\(\\)\n\n# Test 2: Get log statistics\nprint\\(''[2] GET /api/v2/logs/stats''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs/stats'', headers={''X-API-Key'': API_KEY}\\)\nassert r.status_code == 200, f''Expected 200, got {r.status_code}''\ndata = r.json\\(\\)\nprint\\(f''   Date: {data[\"\"date\"\"]}''\\)\nprint\\(f''   Total lines: {data[\"\"total_lines\"\"]}''\\)\nprint\\(f''   Severity levels: {list\\(data[\"\"by_level\"\"].keys\\(\\)\\)[:5]}''\\)\nprint\\(f''   Categories: {list\\(data[\"\"by_category\"\"].keys\\(\\)\\)}''\\)\nprint\\(f''   Top 3 events: {[e[\"\"event\"\"] for e in data[\"\"top_events\"\"][:3]]}''\\)\nprint\\(f''   PASS''\\)\nprint\\(\\)\n\n# Test 3: Filter by category=business\nprint\\(''[3] GET /api/v2/logs?category=business''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}, params={''category'': ''business''}\\)\nassert r.status_code == 200\ndata = r.json\\(\\)\nprint\\(f''   Business logs: {data[\"\"total\"\"]}''\\)\nif data[''logs'']:\n    print\\(f''   Sample events: {[log[\"\"event\"\"] for log in data[\"\"logs\"\"][:3]]}''\\)\nprint\\(f''   PASS''\\)\nprint\\(\\)\n\n# Test 4: Filter by level=error\nprint\\(''[4] GET /api/v2/logs?level=error''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}, params={''level'': ''error''}\\)\nassert r.status_code == 200\ndata = r.json\\(\\)\nprint\\(f''   Error logs: {data[\"\"total\"\"]}''\\)\nprint\\(f''   PASS''\\)\nprint\\(\\)\n\n# Test 5: Filter by event pattern \\(regex\\)\nprint\\(''[5] GET /api/v2/logs?event=session_.*''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}, params={''event'': ''session_.*'', ''per_page'': 5}\\)\nassert r.status_code == 200\ndata = r.json\\(\\)\nprint\\(f''   Session events: {data[\"\"total\"\"]}''\\)\nif data[''logs'']:\n    print\\(f''   Events: {[log[\"\"event\"\"] for log in data[\"\"logs\"\"]]}''\\)\nprint\\(f''   PASS''\\)\nprint\\(\\)\n\n# Test 6: Pagination\nprint\\(''[6] GET /api/v2/logs?page=2&per_page=20''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}, params={''page'': 2, ''per_page'': 20}\\)\nassert r.status_code == 200\ndata = r.json\\(\\)\nprint\\(f''   Page: {data[\"\"page\"\"]}, Per page: {data[\"\"per_page\"\"]}''\\)\nprint\\(f''   Returned: {len\\(data[\"\"logs\"\"]\\)} logs''\\)\nprint\\(f''   PASS''\\)\nprint\\(\\)\n\n# Test 7: Combined filters\nprint\\(''[7] GET /api/v2/logs?category=business&level=info&per_page=10''\\)\nr = requests.get\\(\n    f''{BASE}/api/v2/logs'',\n    headers={''X-API-Key'': API_KEY},\n    params={''category'': ''business'', ''level'': ''info'', ''per_page'': 10}\n\\)\nassert r.status_code == 200\ndata = r.json\\(\\)\nprint\\(f''   Business + Info logs: {data[\"\"total\"\"]}''\\)\nprint\\(f''   Filters applied: {data[\"\"filters_applied\"\"]}''\\)\nprint\\(f''   PASS''\\)\nprint\\(\\)\n\nprint\\(''========================================''\\)\nprint\\(''  ALL TESTS PASSED!''\\)\nprint\\(''========================================''\\)\n\")",
      "Bash(cmd //c \"taskkill /F /PID 140784\")",
      "Bash(cmd //c \"taskkill /F /PID 116840 & taskkill /F /PID 74504\")",
      "Bash(cmd //c \"taskkill /F /PID 72952 & taskkill /F /PID 74504\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\n\nBASE = ''http://localhost:8000''\nAPI_KEY = ''your-api-key-here''\n\nprint\\(''========================================''\\)\nprint\\(''  TEST FINAL - PORT 8000''\\)\nprint\\(''========================================''\\)\nprint\\(\\)\n\n# Test 1: Check OpenAPI schema\nprint\\(''[1] Verifying Logs Endpoints in OpenAPI Schema''\\)\nr = requests.get\\(f''{BASE}/openapi.json''\\)\nif r.status_code == 200:\n    schema = r.json\\(\\)\n    paths = schema.get\\(''paths'', {}\\)\n    logs_paths = [p for p in sorted\\(paths.keys\\(\\)\\) if ''logs'' in p.lower\\(\\)]\n    if logs_paths:\n        print\\(f''   SUCCESS! Found: {logs_paths}''\\)\n    else:\n        print\\(''   FAILED: No logs endpoints found''\\)\n        print\\(''   All endpoints:''\\)\n        for p in sorted\\(paths.keys\\(\\)\\):\n            print\\(f''     - {p}''\\)\nelse:\n    print\\(f''   ERROR: {r.status_code}''\\)\nprint\\(\\)\n\n# Test 2: Test logs endpoint\nprint\\(''[2] Testing GET /api/v2/logs''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}\\)\nprint\\(f''   Status: {r.status_code}''\\)\nif r.status_code == 200:\n    data = r.json\\(\\)\n    print\\(f''   SUCCESS! Total logs: {data[\"\"total\"\"]}''\\)\n    print\\(f''   Returned: {len\\(data[\"\"logs\"\"]\\)} logs''\\)\n    if data[''logs'']:\n        log = data[''logs''][0]\n        print\\(f''   Sample log:''\\)\n        print\\(f''     - Event: {log[\"\"event\"\"]}''\\)\n        print\\(f''     - Category: {log.get\\(\"\"category\"\", \"\"N/A\"\"\\)}''\\)\n        print\\(f''     - Severity: {log.get\\(\"\"severity\"\", \"\"N/A\"\"\\)}''\\)\nelif r.status_code == 404:\n    print\\(''   FAILED: 404 Not Found''\\)\nelse:\n    print\\(f''   ERROR: {r.text[:200]}''\\)\nprint\\(\\)\n\n# Test 3: Test stats endpoint\nprint\\(''[3] Testing GET /api/v2/logs/stats''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs/stats'', headers={''X-API-Key'': API_KEY}\\)\nprint\\(f''   Status: {r.status_code}''\\)\nif r.status_code == 200:\n    data = r.json\\(\\)\n    print\\(f''   SUCCESS!''\\)\n    print\\(f''   Total lines: {data[\"\"total_lines\"\"]}''\\)\n    print\\(f''   Categories: {list\\(data[\"\"by_category\"\"].keys\\(\\)\\)}''\\)\n    print\\(f''   Levels: {list\\(data[\"\"by_level\"\"].keys\\(\\)\\)[:5]}''\\)\nelif r.status_code == 404:\n    print\\(''   FAILED: 404 Not Found''\\)\nelse:\n    print\\(f''   ERROR: {r.text[:200]}''\\)\nprint\\(\\)\n\n# Test 4: Test filter\nprint\\(''[4] Testing Filter \\(category=business\\)''\\)\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}, params={''category'': ''business''}\\)\nprint\\(f''   Status: {r.status_code}''\\)\nif r.status_code == 200:\n    data = r.json\\(\\)\n    print\\(f''   SUCCESS! Business logs: {data[\"\"total\"\"]}''\\)\nelse:\n    print\\(f''   FAILED: {r.status_code}''\\)\nprint\\(\\)\n\nprint\\(''========================================''\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport sys\nsys.path.insert\\(0, ''C:/Users/jfran/axtion/TestBoost''\\)\n\ntry:\n    from src.api.routers import logs\n    print\\(''SUCCESS: logs module imported''\\)\n    print\\(f''Router: {logs.router}''\\)\n    print\\(f''Prefix: {logs.router.prefix}''\\)\n    print\\(f''Routes: {[route.path for route in logs.router.routes]}''\\)\nexcept Exception as e:\n    print\\(f''FAILED to import logs: {e}''\\)\n    import traceback\n    traceback.print_exc\\(\\)\n\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport requests\nimport json\n\nBASE = ''http://localhost:8000''\nAPI_KEY = ''your-api-key-here''\n\nprint\\(''Verification des derniers logs generes...''\\)\nprint\\(\\)\n\n# Get last 30 logs to see what was logged\nr = requests.get\\(f''{BASE}/api/v2/logs'', headers={''X-API-Key'': API_KEY}, params={''per_page'': 30}\\)\nif r.status_code == 200:\n    data = r.json\\(\\)\n    logs = data[''logs'']\n    \n    # Show the most recent logs\n    print\\(''Les 30 derniers logs \\(du plus recent au plus ancien\\):''\\)\n    print\\(''=''*70\\)\n    for log in logs[:30]:\n        event = log.get\\(''event'', ''unknown''\\)\n        path = log.get\\(''extra'', {}\\).get\\(''path'', ''N/A''\\)\n        print\\(f''{event:30s} | {path}''\\)\n    print\\(''=''*70\\)\nelse:\n    print\\(f''ERROR: {r.status_code}''\\)\n\")",
      "Bash(cmd //c \"dir logs\\\\*.log\")",
      "Bash(timeout /t 8 /nobreak)",
      "Bash(cmd //c \"echo. > logs\\\\testboost_20260113.log\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m py_compile src/api/routers/health.py)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m py_compile src/lib/logging.py src/api/routers/health.py)",
      "Bash(cmd //c \"taskkill /F /PID 185112\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nwith open\\(''logs/testboost_20260114.log'', ''r'', encoding=''utf-8''\\) as f:\n    lines = f.readlines\\(\\)\n    errors = [line for line in lines if ''\"\"level\"\": \"\"error\"\"'' in line]\n    print\\(f''Nombre d erreurs: {len\\(errors\\)}''\\)\n    if errors:\n        print\\(''\\\\nDernieres 5 erreurs:''\\)\n        for line in errors[-5:]:\n            if ''AttributeError'' in line or ''RuntimeError'' in line:\n                print\\(line[:300]\\)\n\")",
      "Bash(cmd //c \"netstat -ano | findstr \"\":8000\"\" | findstr \"\"LISTENING\"\"\")",
      "Bash(cmd //c \"taskkill /F /PID 188048\")",
      "Bash(cmd //c \"taskkill /F /PID 117492\")",
      "Bash(cmd //c \"taskkill /F /PID 179888\")",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m uvicorn:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m pytest tests/ -v -k \"step\" --tb=short)",
      "Bash(for i in {1..30})",
      "Bash(done)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" test_background_session_fix.py)",
      "Bash(for i in {1..20})",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -m ruff check src/core/step_executor.py)",
      "Bash(cmd //c \"taskkill /F /PID 121400\")",
      "Bash(cmd //c \"taskkill /F /PID 179588\")",
      "Bash(cmd //c \"dir /s /b test-projects\\\\spring-petclinic-microservices\\\\*Test.java\")",
      "Bash(timeout /t 10 /nobreak)",
      "Bash(cmd //c \"dir /s /b test-projects\\\\spring-petclinic-microservices\\\\spring-petclinic-customers-service\\\\*Test.java\")",
      "Bash(cmd //c \"dir /ad /b test-projects\\\\spring-petclinic-microservices\\\\spring-petclinic-customers-service\")",
      "Bash(cmd //c \"for /f \"\"tokens=5\"\" %a in \\(''netstat -ano ^| findstr \"\":8000\"\" ^| findstr \"\"LISTENING\"\"''\\) do taskkill /F /PID %a\")",
      "Bash(cmd //c \"dir /s /b test-projects\\\\spring-petclinic-microservices\\\\spring-petclinic-customers-service\\\\*Test.java 2>nul\")",
      "Bash(cmd //c:*)",
      "Bash(\"c:/Users/jfran/axtion/TestBoost/.venv/Scripts/python.exe\" -c \"\nimport asyncio\nfrom sqlalchemy import select, text\nfrom src.db import SessionLocal\nfrom src.db.models.session import Session\nfrom src.db.models.step import Step\n\nasync def check_session\\(\\):\n    async with SessionLocal\\(\\) as db:\n        # Get session\n        result = await db.execute\\(\n            select\\(Session\\).where\\(Session.id == ''175ee80d-1407-408c-91d9-da1c3fa433a5''\\)\n        \\)\n        session = result.scalar_one_or_none\\(\\)\n        \n        if session:\n            print\\(f''Session found:''\\)\n            print\\(f''  ID: {session.id}''\\)\n            print\\(f''  Type: {session.session_type}''\\)\n            print\\(f''  Status: {session.status}''\\)\n            print\\(f''  Project: {session.project_path}''\\)\n            print\\(\\)\n        \n        # Get all steps for this session\n        result = await db.execute\\(\n            select\\(Step\\).where\\(Step.session_id == ''175ee80d-1407-408c-91d9-da1c3fa433a5''\\)\n            .order_by\\(Step.sequence\\)\n        \\)\n        steps = result.scalars\\(\\).all\\(\\)\n        \n        print\\(f''Steps \\({len\\(steps\\)}\\):''\\)\n        for step in steps:\n            print\\(f''  {step.sequence}. {step.code} \\({step.name}\\)''\\)\n            print\\(f''     Status: {step.status}''\\)\n            if step.started_at:\n                print\\(f''     Started: {step.started_at}''\\)\n            if step.completed_at:\n                print\\(f''     Completed: {step.completed_at}''\\)\n            if step.error_message:\n                print\\(f''     Error: {step.error_message}''\\)\n            print\\(\\)\n\nasyncio.run\\(check_session\\(\\)\\)\n\")",
      "Bash(python -m py_compile:*)",
      "Bash(cmd /c \"dir /b kill_server.ps1 test_artifact_fix.py 2>nul\")",
      "Bash(powershell.exe -ExecutionPolicy Bypass -File .specify/scripts/powershell/create-new-feature.ps1 -Json -Number 8 -ShortName \"opensource-release\" \"je vais mettre TestBoost en Open source\")",
      "Bash(git merge:*)",
      "Bash(if [ -f .coverage ])",
      "Bash(then python -m coverage report --skip-empty)",
      "Bash(else echo \"No coverage data found\")",
      "Bash(fi)",
      "Bash(powershell.exe -ExecutionPolicy Bypass -File .specify/scripts/powershell/setup-plan.ps1 -Json)",
      "Bash(python analyze_coverage.py:*)",
      "Bash(python test_scenarios.py:*)",
      "Bash(ls:*)",
      "Bash(powershell.exe -ExecutionPolicy Bypass -File .specify/scripts/powershell/check-prerequisites.ps1 -Json)",
      "Bash(powershell -File:*)",
      "Bash(powershell.exe:*)",
      "Bash(while read file)",
      "Bash(do if grep -q -i -E \"\\(AIzaSy|gho_|ghp_|sk-|xox[baprs]-\\)\" \"$file\")",
      "Bash(then echo \"$file\")",
      "Bash([ -f .env ])",
      "Bash(git check-ignore:*)",
      "Bash(git remote set-url:*)",
      "Bash(gh pr close:*)",
      "Bash(gh api:*)",
      "Bash(gh pr view:*)",
      "Bash(pip install:*)",
      "Bash(pre-commit install:*)",
      "Bash(pre-commit run:*)"
    ],
    "deny": [],
    "ask": []
  },
  "enableAllProjectMcpServers": true,
  "enabledMcpjsonServers": [
    "langchain"
  ]
}
